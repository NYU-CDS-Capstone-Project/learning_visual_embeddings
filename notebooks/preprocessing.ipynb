{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from capstone_project.utils import save_plot\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project_dir, data_dir, filename):\n",
    "    filename = os.path.join(project_dir, data_dir, filename)\n",
    "    data = np.load(filename)\n",
    "    data = data.swapaxes(0,1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_buckets_dict(time_buckets):\n",
    "    bucket_idx = 0\n",
    "    buckets_dict = {}\n",
    "    for bucket in time_buckets:\n",
    "        for time in bucket:\n",
    "            buckets_dict[time] = bucket_idx\n",
    "        bucket_idx += 1\n",
    "    return buckets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_differences_dict(num_total_frames):\n",
    "    # min_diff = 0, max_diff = num_total_frames-1\n",
    "    # TODO: NUM_FRAMES_IN_STACK\n",
    "    differences = range(num_total_frames)\n",
    "    differences_dict = {}\n",
    "    for diff in differences:\n",
    "        for i in range(num_total_frames):\n",
    "            if i+diff >= num_total_frames:\n",
    "                break\n",
    "            start_frame, end_frame = i, i+diff\n",
    "            while end_frame < num_total_frames:\n",
    "                differences_dict.setdefault(diff, []).append((start_frame, end_frame))\n",
    "                end_frame += 1\n",
    "    return differences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_at_difference(data, difference, differences_dict, num_videos_per_row, time_buckets_dict):\n",
    "    video_pairs, y = [], []\n",
    "    candidates = differences_dict[difference]\n",
    "    np.random.seed(1337)\n",
    "    idx_pairs = np.random.choice(len(candidates), size=num_videos_per_row)\n",
    "    for row in data:\n",
    "        for idx_pair in idx_pairs:\n",
    "            target1, target2 = candidates[idx_pair]\n",
    "            video_pairs.append([row[target1], row[target2]])\n",
    "            bucket = time_buckets_dict[difference]\n",
    "            y.append(bucket)\n",
    "    return np.array(video_pairs), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paired_data(project_dir, data_dir, plots_dir, filename, time_buckets, num_rows=2, num_videos_per_row=1, force=False):\n",
    "    mean, std = 0, 1\n",
    "    data = load_data(project_dir, data_dir, filename)\n",
    "    imshow(data, mean, std, project_dir, plots_dir)\n",
    "\n",
    "    X_path = os.path.join(project_dir, data_dir, 'X.pkl')\n",
    "    y_path = os.path.join(project_dir, data_dir, 'y.pkl')\n",
    "    if not force and os.path.exists(X_path) and os.path.exists(y_path):\n",
    "        data = None\n",
    "        X = pickle.load(open(X_path, 'rb'))\n",
    "        y = pickle.load(open(y_path, 'rb'))\n",
    "        return X, y\n",
    "    num_total_frames = data.shape[1]\n",
    "    time_buckets_dict = get_time_buckets_dict(time_buckets)\n",
    "    differences_dict = get_frame_differences_dict(num_total_frames)\n",
    "    X, y = np.array([]), np.array([])\n",
    "    for i in range(num_rows):\n",
    "        for difference in range(num_total_frames):\n",
    "            video_pairs, targets = get_samples_at_difference(data, difference, differences_dict, num_videos_per_row, time_buckets_dict)\n",
    "            X = video_pairs if not X.size else np.vstack((X, video_pairs))\n",
    "            y = np.append(y, targets)\n",
    "    pickle.dump(X, open(X_path, 'wb'))\n",
    "    pickle.dump(y, open(y_path, 'wb'))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingMNISTDataset(Dataset):\n",
    "    def __init__(self, X, y, transforms=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        x1 = self.X[index][0]\n",
    "        x2 = self.X[index][1]\n",
    "        y = self.y[index]\n",
    "        return x1, x2, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloader(X, y, test_size, val_size, batch_size, project_dir, plots_dir):\n",
    "    # mean = np.mean(dataset)\n",
    "    # std = np.std(dataset)\n",
    "    # dataset = (dataset - mean)/std\n",
    "    # data_transform = transforms.Compose([\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((mean,), (std,))\n",
    "    # ])\n",
    "\n",
    "    X, y = torch.from_numpy(X), torch.from_numpy(y)\n",
    "    dataset = dataset = MovingMNISTDataset(X, y, transforms=None)\n",
    "\n",
    "    num_test = int(np.floor(test_size*len(dataset)))\n",
    "    num_train_val = len(dataset) - num_test\n",
    "    num_val = int(np.floor(num_train_val*val_size/(1 - test_size)))\n",
    "    num_train = num_train_val - num_val\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(data, mean, std, project_dir, plots_dir):\n",
    "    image_dim = data.shape[-1]\n",
    "    np.random.seed(1337)\n",
    "    images = data[np.random.choice(len(data), size=1)]\n",
    "    images = torch.from_numpy(images)\n",
    "\n",
    "    images = make_grid(images[0].reshape(-1, 1, image_dim, image_dim), nrow=10, padding=5, pad_value=1)\n",
    "    images = images*std + mean  # unnormalize\n",
    "    np_image = images.numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.imshow(np.transpose(np_image, axes=(1, 2, 0)))\n",
    "    plt.tight_layout()\n",
    "    save_plot(project_dir, plots_dir, fig, 'data_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
