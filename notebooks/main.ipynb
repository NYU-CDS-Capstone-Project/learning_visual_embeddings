{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from capstone_project.preprocessing import generate_dataloader\n",
    "from capstone_project.models.embedding_network import EmbeddingNetwork\n",
    "from capstone_project.models.classification_network import ClassificationNetwork\n",
    "from capstone_project.utils import train, test, accuracy, save_plot\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "PROJECT_DIR = '/home/mihir/Desktop/GitHub/nyu/capstone_project/'\n",
    "DATASET = 'moving_mnist'\n",
    "TEST_SIZE, VAL_SIZE = 0.2, 0.2\n",
    "BATCH_SIZE = 64   # input batch size for training\n",
    "N_EPOCHS = 10       # number of epochs to train\n",
    "LR = 0.01        # learning rate\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(PROJECT_DIR, 'data/mnist_test_seq.npy'))\n",
    "data = np.swapaxes(data, 0, 1)\n",
    "train_loader, val_loader, test_loader = generate_dataloader(data, TEST_SIZE, VAL_SIZE, BATCH_SIZE, PROJECT_DIR)\n",
    "\n",
    "if DATASET == 'moving_mnist':\n",
    "    in_dim, in_channels, out_dim = 64, 2, 1024\n",
    "    embedding_hidden_size, classification_hidden_size = 1024, 1024\n",
    "    num_outputs = 6\n",
    "elif DATASET == 'cifar10':\n",
    "    in_dim, in_channels, out_dim = 32, 3, 1024\n",
    "    embedding_hidden_size, classification_hidden_size = 1024, 1024\n",
    "    num_outputs = 10\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "embedding_network = EmbeddingNetwork(in_dim, in_channels, out_dim, embedding_hidden_size).to(DEVICE)\n",
    "classification_network = ClassificationNetwork(out_dim, num_outputs, classification_hidden_size).to(DEVICE)\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "criterion_test = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(list(embedding_network.parameters()) + list(classification_network.parameters()), lr=LR)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    train_loss = train(\n",
    "        embedding_network=embedding_network,\n",
    "        classification_network=classification_network,\n",
    "        criterion=criterion_train,\n",
    "        dataloader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=DEVICE,\n",
    "        epoch=epoch\n",
    "    )\n",
    "\n",
    "    test_loss, test_pred, test_true = test(\n",
    "        network=network,\n",
    "        criterion=criterion_test,\n",
    "        dataloader=test_loader,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    accuracy_train = accuracy(embedding_network, classification_network, train_loader, criterion_test, DEVICE)\n",
    "    accuracy_test = accuracy(embedding_network, classification_network, test_loader, criterion_test, DEVICE)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "\n",
    "    print('TRAIN Epoch: {}\\tAverage loss: {:.4f}, Accuracy: {:.0f}%'.format(epoch, train_loss, accuracy_train))\n",
    "    print('TEST  Epoch: {}\\tAverage loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(epoch, test_loss, accuracy_test))\n",
    "\n",
    "\n",
    "total_parameters_dict = dict(embedding_network.named_parameters())\n",
    "total_parameters_dict.update(dict(classification_network.named_parameters()))\n",
    "embedding_output1 = embedding_network(train_loader.dataset[0][0].to(DEVICE))\n",
    "embedding_output2 = embedding_network(train_loader.dataset[1][0].to(DEVICE))\n",
    "classification_input = torch.dot(embedding_output1, embedding_output2)\n",
    "classification_output = classification_network(classification_input)\n",
    "make_dot(classification_output, params=total_parameters_dict)\n",
    "\n",
    "with torch.onnx.set_training(network, False):\n",
    "    embedding_output1 = embedding_network(train_loader.dataset[0][0].to(DEVICE))\n",
    "    embedding_output2 = embedding_network(train_loader.dataset[1][0].to(DEVICE))\n",
    "    classification_input = torch.dot(embedding_output1, embedding_output2)\n",
    "    trace, _ = torch.jit.get_trace_graph(classification_network, args=(classification_input,))\n",
    "make_dot_from_trace(trace)\n",
    "\n",
    "loss_history_df = pd.DataFrame({\n",
    "    'train': train_loss_history,\n",
    "    'test': test_loss_history,\n",
    "})\n",
    "\n",
    "fig = plt.figure()\n",
    "loss_history_df.plot(alpha=0.5, figsize=(10,8))\n",
    "save_plot(PROJECT_DIR, fig, 'loss_vs_iterations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
